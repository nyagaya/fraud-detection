# fraud-detection
Predict fraud in credit card transaction dataset.

Implement a couple of machine learning techniques that accurately predicts fraudulent credit card transactions. In addition to the machine learning applications, explore the data via EDA to gain a better understanding of features, although this maybe limited considering all numeric features were reduced to principal components of the original variables.

Data description: https://www.kaggle.com/dalpozz/creditcardfraud

This is a current Kaggle data set where the task is to predict fraud. It contains credit card transactions made in 2013 by European card holders, recorded over a two-day period. It has about 285 thousand observations and 31 features. In total, there are only 492 fraudulent transactions (0.17%) and 285 thousand non-fraud transactions. For privacy reasons, all numeric features were reduced to lower dimension before distribution, using PCA into 28 principal components V1 through V28. For similar reasons, no additional feature descriptions were provided. Other variables were Time (time elapsed after the first transaction) and Amount (charged transaction) as well as the class label where 1 represented fraud event and 0 otherwise. A major limitation in the data was the severe class-imbalance which represented a significant challenge in correctly classifying fraud.

Data details and design decisions:
Implemented logistic regression and random forest machine learning techniques. Iterative KDD process, from data understanding, data preprocessing, exploratory data analysis, data reduction/scaling and modeling as well as selecting the final model. Considering the class imbalance, I employed resampling techniques, different measures of model accuracy as well as ensemble learning. I then trained two models on the class imbalanced data, with modest predictions – figures 2/3, after which we balanced the data and trained a final random forest model that achieved significantly better results on the unseen class-imbalanced test set – figure 1. However, it should be noted that while the final model has recall = 92% on the class of interest (overall recall = 98%), precision materially suffered. However, in fraud detection, my view is that we want to maximize recall on the class of interest at the expense of precision – i.e. we care more about predicting that what we predict as fraud, is fraud. So, while our precision in the final model positive class is negligible, we are okay with that.
